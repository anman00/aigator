# AiGator

## Project Description
AiGator is an intelligent query routing system designed to streamline user queries to the most appropriate large language model (LLM). Using an intent detection mechanism, AiGator automatically identifies the domain of a user query and routes it to the corresponding pre-mapped LLM. If no match is found, the query is routed to a default fallback model, ensuring seamless query resolution.

---

## Table of Contents
- [Project Description](#project-description)
- [Table of Contents](#table-of-contents)
- [How to Install and Run the Project](#how-to-install-and-run-the-project)
- [How to Use the Project](#how-to-use-the-project)
- [Credits](#credits)
- [License](#license)

---

## How to Install and Run the Project

### Prerequisites
1. **Python**: Ensure Python 3.7 or higher is installed on your system.
2. **Pip**: Ensure you have `pip` for managing Python packages.
3. **Streamlit**: Install Streamlit for running the app.
4. **OpenRouter API Key**: Obtain an API key from [OpenRouter](https://openrouter.ai/).

### Installation Steps
1. Clone the repository:
    ```bash
    git clone https://github.com/your-username/AiGator.git
    cd AiGator
    ```
2. Install the required dependencies:
    ```bash
    pip install -r requirements.txt
    ```

### Running the Application
1. Launch the Streamlit app:
    ```bash
    streamlit run main.py
    ```
2. Open the provided URL in your web browser to interact with the app.

---

## How to Use the Project
1. **Enter a Query**: Input your question or query in the provided text box.
2. **Click the "Ask" Button**: Allow AiGator to detect the intent and route your query.
3. **View the Response**: AiGator will display the detected intent, the model being used, and the response generated by the LLM.

### Features:
- **Intent Detection**: AiGator identifies the query domain from a predefined set of categories.
- **Model Mapping**: Queries are routed to the LLM best suited for the detected intent.
- **Fallback Mechanism**: If no intent matches, the query is routed to a default fallback model (`meta-llama/llama-3.1-70b-instruct:free`).
- **Error Handling**: Graceful handling of rate limits or API issues.

---

## Credits
- **Author**: [Your Name or GitHub Handle](https://github.com/your-username)
- **Contributors**: Special thanks to the teams behind [OpenRouter](https://openrouter.ai/) and the LLM providers.

---

## License
This project is licensed under the [MIT License](https://opensource.org/licenses/MIT). Feel free to use, modify, and distribute this project as per the terms of the license.

