import streamlit as st
import requests
import json

# Full intent-to-LLM mapping with 35 intents
LLM_MAPPING = {
    "healthcare": "microsoft/phi-3-medium-128k-instruct:free",
    "mathematics": "meta-llama/llama-3.1-405b-instruct:free",
    "programming": "huggingfaceh4/zephyr-7b-beta:free",
    "science": "qwen/qwen-2-7b-instruct:free",
    "education": "meta-llama/llama-3.1-405b-instruct:free",
    "general knowledge": "huggingfaceh4/zephyr-7b-beta:free",
    "travel": "mistralai/mistral-7b-instruct:free",
    "entertainment": "qwen/qwen-2-7b-instruct:free",
    "finance": "microsoft/phi-3-medium-128k-instruct:free",
    "technology": "meta-llama/llama-3.1-405b-instruct:free",
    "shopping": "huggingfaceh4/zephyr-7b-beta:free",
    "history": "meta-llama/llama-3.1-405b-instruct:free",
    "geography": "qwen/qwen-2-7b-instruct:free",
    "art and design": "mistralai/mistral-7b-instruct:free",
    "music": "mistralai/mistral-7b-instruct:free",
    "sports": "huggingfaceh4/zephyr-7b-beta:free",
    "fitness and wellness": "google/gemini-exp-1114",
    "food and cooking": "mistralai/mistral-7b-instruct:free",
    "parenting and childcare": "huggingfaceh4/zephyr-7b-beta:free",
    "language learning": "meta-llama/llama-3.1-405b-instruct:free",
    "business and management": "microsoft/phi-3-medium-128k-instruct:free",
    "marketing and advertising": "huggingfaceh4/zephyr-7b-beta:free",
    "job search and career advice": "meta-llama/llama-3.1-405b-instruct:free",
    "home improvement and diy": "huggingfaceh4/zephyr-7b-beta:free",
    "relationships and dating": "google/gemini-exp-1114",
    "psychology and self-help": "google/gemini-exp-1114",
    "law and legal advice": "microsoft/phi-3-medium-128k-instruct:free",
    "environmental issues": "meta-llama/llama-3.1-405b-instruct:free",
    "astronomy and space exploration": "qwen/qwen-2-7b-instruct:free",
    "fashion and style": "mistralai/mistral-7b-instruct:free",
    "gaming": "qwen/qwen-2-7b-instruct:free",
    "mythology and folklore": "mistralai/mistral-7b-instruct:free",
    "spirituality and religion": "mistralai/mistral-7b-instruct:free",
    "pets and animal care": "google/gemini-exp-1114",
    "miscellaneous": "meta-llama/llama-3.1-405b-instruct:free",  # Default fallback model
}

# OpenRouter API Key and App Configuration
OPENROUTER_API_KEY = "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"

# Function to classify intent using LLM
def classify_intent_llm(query, intents):
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
    }
    # Prepare the prompt with all intents
    prompt = (
        f"Classify the following query into one of these intents: {', '.join(intents)}. "
        "Respond with the exact intent from the list. If the query doesn't match any intent, respond with 'miscellaneous'. "
        f"Query: {query}"
    )
    data = {
        "model": "meta-llama/llama-3.1-405b-instruct:free",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 50,
    }
    response = requests.post("https://openrouter.ai/api/v1/chat/completions", headers=headers, data=json.dumps(data))
    if response.status_code == 200:
        response_data = response.json()
        return response_data["choices"][0]["message"]["content"].strip().lower()
    else:
        raise Exception(f"Error {response.status_code}: {response.text}")

# Function to fetch response from the selected LLM
def fetch_response(query, llm_name):
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
    }
    data = {
        "model": llm_name,
        "messages": [{"role": "user", "content": query}],
        "max_tokens": 300,
    }
    response = requests.post("https://openrouter.ai/api/v1/chat/completions", headers=headers, data=json.dumps(data))
    if response.status_code == 200:
        response_data = response.json()
        return response_data["choices"][0]["message"]["content"].strip()
    else:
        raise Exception(f"Error {response.status_code}: {response.text}")

# Streamlit Interface
st.title("AiGator - Intelligent Query Router")

# User Query Input
user_query = st.text_input("Enter your query:")

if st.button("Ask"):
    if user_query:
        with st.spinner("Classifying intent..."):
            try:
                # Step 1: Classify Intent
                intent_list = list(LLM_MAPPING.keys())
                detected_intent = classify_intent_llm(user_query, intent_list)
                st.success(f"Detected Intent: {detected_intent.capitalize()}")

                # Step 2: Map Intent to LLM
                selected_llm = LLM_MAPPING.get(detected_intent, LLM_MAPPING["miscellaneous"])
                st.info(f"Using Model: {selected_llm}")

                # Step 3: Fetch Response from LLM
                with st.spinner("Fetching response from LLM..."):
                    response = fetch_response(user_query, selected_llm)
                    st.write("### Response")
                    st.write(response)

            except Exception as e:
                st.error(f"Error: {e}")
    else:
        st.warning("Please enter a query.")
